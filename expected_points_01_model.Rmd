---
title: "CFB Expected Points Added"
author: "Phil Henrickson"
date: "6/7/2022"
output: 
  html_document:
    toc: TRUE #adds a Table of Contents
    theme: cerulean
    number_sections: TRUE #number your headings/sections
    toc_float: TRUE #let your ToC follow you as you scroll
    keep_md: no
    fig.caption: yes
    css: "styles.css"
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = F,
                      error = F,
                      warning=F,
                      dev="png",
                      fig.width = 10,
                      fig.height = 6)

options(knitr.duplicate.label = "allow")

options(scipen=999)

```


```{r connect to snowflake}

library(DBI)
library(odbc)
library(RODBC)
library(keyring)

# connect to snowflake
myconn <- DBI::dbConnect(odbc::odbc(),
                         "SnowflakeDSII",
                         Database = "CFB_DEMO",
                         warehouse = "DEMO_WH",
                         uid="phil.henrickson",
                         pwd=keyring::key_get("AE_Snowflake"))

```

```{r packages, include=F} 

source(here::here("scripts/load_packages.R"))
library(jsonlite)
library(forcats)
conflict_prefer("lag", "dplyr")

library(flextable)
set_flextable_defaults(theme_fun = theme_alafoli,
                       font.color = "grey10",
                       font.size=8,
                       padding.bottom = 6, 
                       padding.top = 6,
                       padding.left = 6,
                       padding.right = 6,
                       background.color = "white")

```

```{r load functions}

source(here::here("functions/theme_phil.R"))
source(here::here("functions/clean_plays_func.R"))
source(here::here("functions/make_time_features_func.R"))
source(here::here("functions/expected_points_func.R"))
source(here::here("functions/get_drive_score_events.R"))
source(here::here("functions/assign_play_score_events.R"))
rm(a)

```

```{r query data from snowflake}

### pull from snowflake
# get plays
plays_raw = DBI::dbGetQuery(myconn,
                             paste('SELECT * FROM CFB_DEMO.CFD_RAW.PLAY_BY_PLAY')) %>%
        as_tibble() %>%
        mutate(TIME = gsub('\\{|}|"', '', CLOCK)) %>%
        separate(TIME, into=c("MINUTES", "SECONDS"), sep=",") %>%
        mutate(MINUTES = as.numeric(gsub("minutes:", "", MINUTES))) %>% 
        mutate(SECONDS = as.numeric(gsub("seconds:", "", SECONDS))) %>%
        mutate(MINUTES_IN_HALF = case_when(PERIOD == 1 ~ MINUTES+ 15,
                                           PERIOD == 2 ~ MINUTES,
                                           PERIOD == 3 ~ MINUTES + 15,
                                           PERIOD == 4 ~ MINUTES)) %>%
        mutate(SECONDS_IN_HALF = MINUTES_IN_HALF*60 + SECONDS) %>%
        # flag if seconds in half is invalid
        mutate(FLAG_SECONDS_IN_HALF = case_when(SECONDS_IN_HALF > 1800 ~ 1,
                                                TRUE ~ 0)) %>%
        # convert IDs to numeric
        mutate(ID = as.numeric(ID),
               DRIVE_ID = as.numeric(DRIVE_ID)) %>%
        rename(PLAY_ID = ID) %>%
        group_by(GAME_ID) %>%
        # sort each game by drive
        arrange(PLAY_ID) %>% 
        ungroup() %>%
        # clean up PERIOD by game
        mutate(STATUS_PERIOD = case_when(PERIOD == 0 & nchar(PLAY_TEXT) <=1 ~ 'Drop',
                                        PERIOD == 0 ~ 'Take Previous Value',
                                        TRUE ~ 'Valid')) %>%
        filter(STATUS_PERIOD != 'Drop') %>%
        mutate(PERIOD = case_when(STATUS_PERIOD == 'Take Previous Value' ~ lag(PERIOD, 1),
                                  TRUE ~ PERIOD)) %>%
        ungroup() %>% 
        # make half feature
        mutate(HALF = case_when(PERIOD == 1 ~ 'First Half',
                                PERIOD == 2 ~ 'First Half',
                                PERIOD == 3 ~ 'Second Half',
                                PERIOD == 4 ~ 'Second Half',
                                TRUE ~ 'OT')) %>%
        # then clean up the down
        mutate(FLAG_DOWN = case_when(DOWN %in% c(1, 2, 3, 4) ~ 0,
                                       TRUE ~ 1)) %>%
        mutate(DOWN = case_when(DOWN %in% c(1, 2, 3, 4) ~ DOWN,
                                TRUE ~ -1)) %>%
        # then flag the distance
        mutate(FLAG_DISTANCE = case_when((DISTANCE < 0 | DISTANCE >=99) ~ 1,
                                         TRUE ~ 0)) %>%
        # flag yard lines that are outside correct
        mutate(FLAG_YARD_LINE = case_when(YARD_LINE < 0 | YARD_LINE > 100 ~ 1,
                                          TRUE ~ 0))

# get games
games_raw = DBI::dbGetQuery(myconn,
                             paste('SELECT * FROM CFB_DEMO.CFD_RAW.ANALYSIS_GAMES')) %>%
        as_tibble() %>%
        mutate(GAME_DATE = as.Date(START_DATE)) %>%
        arrange(START_DATE)
        
# get drives
drives_raw = DBI::dbGetQuery(myconn,
                              paste('SELECT * FROM CFB_DEMO.CFD_RAW.DRIVES')) %>%
        as_tibble() %>%
        mutate(ID = as.numeric(ID),
               GAME_ID = as.numeric(GAME_ID)) %>%
        rename(DRIVE_ID = ID) %>%
        # get drive time features
        # start of drive
        mutate(START_TIME = gsub('\\{|}|"', '', START_TIME)) %>%
        separate(START_TIME, into=c("START_MINUTES", "START_SECONDS"), sep=",") %>%
        mutate(START_MINUTES = as.numeric(gsub("minutes:", "", START_MINUTES))) %>% 
        mutate(START_SECONDS = as.numeric(gsub("seconds:", "", START_SECONDS))) %>%
        # end of drive
        mutate(END_TIME = gsub('\\{|}|"', '', END_TIME)) %>%
        separate(END_TIME, into=c("END_MINUTES", "END_SECONDS"), sep=",") %>%
        mutate(END_MINUTES = as.numeric(gsub("minutes:", "", END_MINUTES))) %>% 
        mutate(END_SECONDS = as.numeric(gsub("seconds:", "", END_SECONDS))) %>%
        # duration of drive
        mutate(ELAPSED = gsub('\\{|}|"', '', ELAPSED)) %>%
        separate(ELAPSED, into=c("ELAPSED_MINUTES", "ELAPSED_SECONDS"), sep=",") %>%
        mutate(ELAPSED_MINUTES = as.numeric(gsub("minutes:", "", ELAPSED_MINUTES))) %>% 
        mutate(ELAPSED_SECONDS = as.numeric(gsub("seconds:", "", ELAPSED_SECONDS))) 
        
```


```{r drives join with games, include=F}

drives_raw %>%
        left_join(., games_raw %>%
                          select(SEASON, SEASON_TYPE, GAME_ID, HOME_CONFERENCE, AWAY_CONFERENCE, HOME_DIVISION, AWAY_DIVISION),
                  by = c("GAME_ID")) %>%
        group_by(SEASON, SEASON_TYPE) %>%
        count() %>%
        spread(SEASON_TYPE, n) %>%
        select(SEASON, regular, postseason)

```

```{r apply clean up functions}

# now get scoring events for the drives data
drives_score_events = drives_raw %>%
        # run through score events function
        get_drive_score_events()

```

```{r now join this with plays}

# now join with plays
plays_score_events = plays_raw %>%
        left_join(.,
                  drives_score_events %>%
                          select(GAME_ID,
                                 DRIVE_ID,
                                 HOME, 
                                 AWAY,
                                 LAST_DRIVE_HALF,
                                 END_HOME_SCORE,
                                 END_AWAY_SCORE,
                                 SCORE_EVENT,
                                 NEXT_SCORE_EVENT),
                  by = c("GAME_ID",
                         "DRIVE_ID",
                         "HOME", 
                         "AWAY")) %>%
        # now join with games to get seasons
        left_join(.,
                  games_raw %>%
                          select(GAME_ID,
                                 SEASON,
                                 SEASON_TYPE,
                                 HOME_TEAM,
                                 AWAY_TEAM,
                                 HOME_DIVISION,
                                 AWAY_DIVISION),
                  by = c("GAME_ID")) %>%
        # now assign offense defense score events using function
        assign_play_score_events()
       
```

# Defining Expected Points

In this notebook I develop and explore an expected points model at the play level for evaluating college football offenses and defenses. The goal of this analysis is to place a value on offensive/defensive plays in terms of their contribution's to a team's expected points. 

The data comes from collegefootballdata.com, which has play by play data on games from 2000 to present. Each observation represents one play in a game, in which we know the team, the situation (down, time remaining), and the location on the field (yards to go, yards to reach end zone). We have information about the types of plays called as well in a text field.

Due to data quality issues, I focus my analysis on the years from 2007 and onwards.

## Sequences of Play

For each play in a game, I model the probability of the next scoring event that will occur within the same half for either team. This means the analysis is not at the *drive* level, but at what I dub the *sequence* level. For any given play, the next scoring event can take on one of seven outcomes:

* Touchdown (7 points)
* Field goal (3 points)
* Safety (2 points)
* No Score (0 points)
* Opp safety (-2 points)
* Opp field goal (-3 points)
* Opp touchdown (-7 points)

Suppose we have two teams, A and B, playing in a game. Team A receives the opening kickoff, drives for a few plays, and then punts. Team B takes over, which starts drive 2, and they drive for a few plays before also punting. Team A then manages to put together a drive that finally scores. 

```{r make sim tibble 1}

tibble(OFFENSE = c("A", "B", "A"),
       DEFENSE =  c("B", "A", "B"),
       DRIVE = c(1, 2, 3),
       DRIVE_RESULT = c("PUNT", "PUNT", "TD"),
       SCORE_EVENT = c(NA, NA, "OFFENSE TD")) %>%
        flextable() %>%
        autofit()

```


All plays on these three drives are one **sequence**. The outcome of this sequence is the points scored by Team A - if they score a touchdown, their points from this sequence is 7 (assuming for now they make the extra point). Team B's points from this sequence is -7 points. 

This means that each one of these play was leading up to the **Next Scoring Event** of Team A scoring, which was the outcome we assign to each drive (and play) in that sequence.

```{r make sim tibble 2}

tibble(OFFENSE = c("A", "B", "A"),
       DEFENSE =  c("B", "A", "B"),
       SEQUENCE = c(1, 1, 1),
       DRIVE = c(1, 2, 3),
       DRIVE_RESULT = c("PUNT", "PUNT", "TD"),
       SCORE_EVENT = c(NA, NA, "OFFENSE TD"),
       NEXT_SCORE_EVENT = c("TEAM_A TD", "TEAM_A TD", "TEAM_A TD")) %>%
        flextable() %>%
        autofit()

```

If the team on offense drives down and scores a TD/FG, this will end the sequence. If the team on offense does not score but punts or turns the ball over, the sequence will continue with the other team now on offense. The sequence will continue until either one team scores, or the half comes to an end. From this, a sequence begins at kickoff and ends at the next kick off. When Team A kicks off to Team B to start drive 4, we start our next sequence, which will end either with one team scoring or at the end of the half. 

Why model the outcome of sequences rather than individual drives? Individual plays have the potential to affect both team's chances of scoring, positively or negatively, and we want our model to directly capture this. If an offense turns the ball over at midfield, they are not only hurting their own chances of scoring, they are increasing the other team's chance of scoring. The value of a play in terms of expected points is function of how both team's probabilities are affected by the outcome.

## Defining Expected Points

A team's expected points is sum of the probability of each possible scoring event multiplied by the points of that event. For this analysis, I assume that touchdowns equate to 7 rather than 6 points, assuming that extra points will be made. I can later bake in the actual probability of making extra points, but this will be a simplification for now.

For a given play $i$ for  Team $A$, we can compute Team A's expected points using the following:

$$ {Expected Points}_A = \\Pr(TD)*7 + \\ Pr(FG)*3 + \\Pr(Safety)*2 + \\ Pr(No Score)*0 + \\ Pr(Opp. Safety)*-2 + \\ Pr(Opp. FG) * -3 +\\ Pr(Opp. TD) * -7  $$

How do we get the probabilities of each scoring event? We learn these from historical data by using a model - I train a multinomial logistic regression model on many seasons worth of college football plays to learn how situations on the field affect the probability of the next scoring event. 

## Next Scoring Event

The outcome for our analysis is the **NEXT_SCORE_EVENT**. Each play in a given sequence contributes to the eventual outcome of the sequence. Here we can see an example of one game and its drives:

```{r show a full game of sequences}

drives_score_events %>%
        left_join(.,
                  games_raw %>%
                          select(GAME_ID,
                                 SEASON,
                                 HOME_TEAM,
                                 AWAY_TEAM),
                  by = c("GAME_ID")) %>%
        filter(HOME_TEAM == 'Texas A&M' & AWAY_TEAM == 'Florida') %>%
        filter(SEASON == 2012) %>%
        select(SEASON, HOME, AWAY, HALF, DRIVE_NUMBER, END_HOME_SCORE, END_AWAY_SCORE, NEXT_SCORE_EVENT) %>%
        rename(HOME_SCORE = END_HOME_SCORE,
               AWAY_SCORE = END_AWAY_SCORE) %>%
        mutate(SEASON = as.character(SEASON)) %>%
        flextable() %>%
        autofit()
        
```

For this game, we can filter to the plays that took place in the lead up to first score event. In this case, the first sequence included one drive and ended when Texas A&M kicked a field goal.

```{r zoom in on a sequence}

plays_score_events %>%
        filter(HOME_TEAM == 'Texas A&M' & AWAY_TEAM == 'Florida') %>%
        filter(SEASON == 2012) %>%
        filter(DRIVE_NUMBER == 1) %>%
        select(OFFENSE, DEFENSE, DRIVE_NUMBER, DOWN, DISTANCE, YARDS_TO_GOAL, PLAY_TEXT, NEXT_SCORE_EVENT_OFFENSE) %>%
        rename(YTG = YARDS_TO_GOAL) %>%
        rename(DRIVE = DRIVE_NUMBER,
               NEXT_SCORE_EVENT = NEXT_SCORE_EVENT_OFFENSE) %>%
        flextable() %>%
        autofit()
        
```

If we look at another sequence in the second half, there were multiple drives before a team was able to score in that sequence. The next scoring event is always defined from the perspective of the offense.

```{r zoom in on another sequence}

plays_score_events %>%
        filter(HOME_TEAM == 'Texas A&M' & AWAY_TEAM == 'Florida') %>%
        filter(SEASON == 2012) %>%
        filter(DRIVE_NUMBER>=9 & DRIVE_NUMBER <=14) %>%
        select(OFFENSE, DEFENSE, DRIVE_NUMBER, DOWN, DISTANCE, YARDS_TO_GOAL, PLAY_TEXT, NEXT_SCORE_EVENT_OFFENSE) %>%
        rename(YTG = YARDS_TO_GOAL) %>%
        rename(DRIVE = DRIVE_NUMBER,
               NEXT_SCORE_EVENT = NEXT_SCORE_EVENT_OFFENSE) %>%
        flextable() %>%
        autofit()
        
```

# Modeling Expected Points

Our goal is to understand how individual plays contribute to a team's **expected points**, or the average points teams should expect to have given their situation (down, time, possession). 

For instance, in the first drive of the Texas A&M-Florida game in 2012,  Texas A&M received the ball at their own 25 yard line to open the game. The simplest intuition of expected points is to ask, for teams starting at the 25 yard line at the beginning of a game, how many points do they typically go on to score? The answer is to look at all starting drives with 75 yards to go and see what the eventual next scoring event was for each of these plays - we take the average of all of the points that followed from this situation.

```{r expected points given situation}

plays_score_events %>%
        filter(!is.na(NEXT_SCORE_EVENT_OFFENSE)) %>%
        filter(DOWN %in% c(1,2,3,4)) %>%
        filter(!grepl("kick", tolower(PLAY_TEXT))) %>%
        filter(YARDS_TO_GOAL == 75 & DRIVE_NUMBER ==1) %>%
        group_by(NEXT_SCORE_EVENT_OFFENSE, YARDS_TO_GOAL, DRIVE_NUMBER) %>%
        count(sort=T) %>% 
        ungroup() %>%
        mutate(prop = n / sum(n)) %>%
        mutate_if(is.numeric, round, 3) %>%
        flextable() %>%
        autofit() 

plays_score_events %>%
       # filter(SEASON >=2010) %>%
        filter(!is.na(NEXT_SCORE_EVENT_OFFENSE)) %>%
        filter(DOWN %in% c(1,2,3,4)) %>%
        filter(YARDS_TO_GOAL == 75 & DRIVE_NUMBER ==1) %>%
        group_by(YARDS_TO_GOAL, DRIVE_NUMBER) %>%
        summarize(expected_points = mean(NEXT_SCORE_EVENT_OFFENSE_DIFF),
                  n = n(),
                  .groups = 'drop') %>%
        mutate_if(is.numeric, round, 2) %>%
        flextable() %>%
        autofit()

```

In this case, this means teams with the ball at their own 25 to start the game generally obtained more points on the ensuing sequence than their opponents, so they have a slightly positive expected points.

But, this is also a function of the down. If we look at the expected points for a team in this situation in first down vs a team in this situation for fourth down, we should see a drop in their expected points - by the time you hit fourth down, if you haven't moved from the 25, your expected points drops into the negatives, as you will now be punting the ball back to your opponent and it becomes more probable that they score than you.

```{r how does this vary as a function of }

plays_score_events %>%
        filter(!is.na(NEXT_SCORE_EVENT_OFFENSE)) %>%
        filter(YARDS_TO_GOAL == 75  & DRIVE_NUMBER ==1) %>%
        filter(DOWN %in% c(1,2,3,4)) %>%
        group_by(YARDS_TO_GOAL, DOWN, NEXT_SCORE_EVENT_OFFENSE) %>%
        count() %>%
        mutate(DOWN = paste("DOWN", DOWN, sep="_")) %>%
        spread(DOWN, n) %>%
        arrange(NEXT_SCORE_EVENT_OFFENSE) %>%
        arrange(desc(`DOWN_4`)) %>%
        flextable() %>%
        autofit()

plays_score_events %>%
        filter(YARDS_TO_GOAL == 75  & DRIVE_NUMBER ==1) %>%
        filter(DOWN %in% c(1,2,3,4)) %>%
        group_by(YARDS_TO_GOAL, DOWN) %>%
        summarize(expected_points = mean(NEXT_SCORE_EVENT_OFFENSE_DIFF, na.rm=T),
                  n = n(),
                  .groups = 'drop') %>%
        mutate_if(is.numeric, round, 2) %>%
        flextable() %>%
        autofit()

```

The fact that the expected point changes based on the down and yard line allows us to look at the difference between expected points from play to play - the difference in expected points based on how the situation changed allows us to compute the Expected Points *Added* from a single play.

For any given play, we get a sense of the expected points a team can expect from their situation. For instance, if we look at all total plays in a game, how do expected points vary as a function of a team's distance from their opponent's goal line?

```{r expected points as a function of yard line for opening}

plays_score_events %>%
        filter(!grepl("kick", tolower(PLAY_TYPE))) %>%
        filter(!is.na(NEXT_SCORE_EVENT_OFFENSE)) %>%
        filter(DOWN %in% c(1,2,3,4)) %>%
        filter(YARD_LINE < 100 & YARD_LINE > 0) %>%
      #  mutate(YARD_LINE_5 = plyr::round_any(YARDS_TO_GOAL, 5, floor)) %>%
     #   group_by(YARDS_TO_GOAL) %>%
        group_by(YARDS_TO_GOAL) %>%
        summarize(expected_points = mean(NEXT_SCORE_EVENT_OFFENSE_DIFF, na.rm=T),
                  n = n()) %>%
        ggplot(., aes(x=YARDS_TO_GOAL,
                      y=expected_points))+
        geom_line()+
        geom_point(aes(size=n))+
        theme_phil()+
        geom_hline(yintercept = 0,
                   linetype = 'dashed')+
        scale_x_reverse()

```

This should make sense - if you're backed up against your own end zone, your opponent has higher expected points because they are, historically, more likely to have the next scoring event, either by gaining good field advantage after you punt or by getting a safety. We can see this if we just look at the proportion of next scoring events based on the offense's position on the field.

```{r look at outcomes by yards to goal}

# make my own color ramp
my_col = colorRampPalette(c("blue", "white", "red"))
score_palette = c(my_col(6)[1:3], "grey80", my_col(6)[4:6])

plays_score_events %>%
        filter(!grepl("kickoff", tolower(PLAY_TYPE))) %>%
        filter(!is.na(NEXT_SCORE_EVENT_OFFENSE)) %>%
        filter(DOWN %in% c(1,2,3,4)) %>%
        filter(YARD_LINE < 100 & YARD_LINE > 0) %>%
      #  mutate(YARD_LINE_5 = plyr::round_any(YARDS_TO_GOAL, 5, floor)) %>%
     #   group_by(YARDS_TO_GOAL) %>%
        group_by(YARDS_TO_GOAL, NEXT_SCORE_EVENT_OFFENSE) %>%
        count() %>%
        ggplot(., aes(x=YARDS_TO_GOAL,
                      fill = NEXT_SCORE_EVENT_OFFENSE,
                      y=n))+
        geom_col(position = 'fill')+
        scale_fill_manual(values = score_palette)+
       # scale_fill_viridis_d(option = 'B')+
        theme_phil()+
        scale_x_reverse()

```

From this, when we see an offense move the ball up the field on a given play, we will generally see their expected points go up. The difference in expected points before the snap and after the snap is the value added (positively or negatively) by the play.

But, it's not just position on the field - it's also about the situation. If we look at how expected points varies by the down, we should see that fourth downs have lower expected points.

```{r look at expected points by down and field position}

plays_score_events %>%
        filter(PLAY_TYPE != 'Timeout') %>%
        filter(!grepl("kickoff", tolower(PLAY_TYPE))) %>%
        filter(!is.na(NEXT_SCORE_EVENT_OFFENSE)) %>%
        filter(DOWN %in% c(1,2,3,4)) %>%
        filter(YARD_LINE < 100 & YARD_LINE > 0) %>%
      #  mutate(YARD_LINE_5 = plyr::round_any(YARDS_TO_GOAL, 5, floor)) %>%
     #   group_by(YARDS_TO_GOAL) %>%
        group_by(YARDS_TO_GOAL, DOWN) %>%
        summarize(expected_points = mean(NEXT_SCORE_EVENT_OFFENSE_DIFF, na.rm=T),
                  n = n(),
                  .groups = 'drop') %>%
        mutate(DOWN = factor(DOWN)) %>%
        ggplot(., aes(x=YARDS_TO_GOAL,
                      group = DOWN,
                      color = DOWN,
                      y=expected_points))+
        geom_point(aes(size=n))+
        geom_line(stat = 'smooth',
                  formula = 'y ~ x',
                  method = 'loess',
                  span = 0.25)+
        theme_phil()+
        geom_hline(yintercept = 0,
                   linetype = 'dotted')+
        scale_x_reverse()+
        scale_color_viridis_d()

```

We also have other features like distance to convert the first down (filtering here to plays with a maximum of 30 yards to go, as we start to run out of data at higher values and it looks wonky).

```{r distance remaining}

plays_score_events %>%
        filter(SEASON_TYPE == 'regular') %>%
        filter(FLAG_SECONDS_IN_HALF != 1) %>%
        filter(!grepl("kickoff", tolower(PLAY_TYPE))) %>%
        filter(!is.na(NEXT_SCORE_EVENT_OFFENSE)) %>%
        filter(DOWN %in% c(1,2,3,4)) %>%
        filter(YARD_LINE < 100 & YARD_LINE > 0) %>%
        mutate(SECONDS_IN_HALF = plyr::round_any(SECONDS_IN_HALF, 5, ceiling)) %>%
        filter(DISTANCE > 0 & DISTANCE<=30) %>%
        group_by(DOWN, DISTANCE, NEXT_SCORE_EVENT_OFFENSE) %>%
        mutate(DOWN = paste("DOWN", DOWN, sep="_")) %>%
        count() %>%
        ggplot(., aes(x=DISTANCE,
                      fill = NEXT_SCORE_EVENT_OFFENSE,
                      y=n))+
        #geom_col()+
        facet_wrap(DOWN ~., ncol = 2) +
        geom_bar(position = 'fill',
                 stat='identity',
                 color = NA)+
        scale_fill_manual(values = score_palette)+
       # scale_fill_viridis_d(option = 'B')+
        theme_phil()

```

And we also have info on time remaining in the half - as we might expect, the proportion of drives leading to no scoring goes up as the amount of time remaining in the half goes down.

```{r look at outcomes as a function of time remaining}

plays_score_events %>%
        filter(SEASON_TYPE == 'regular') %>%
        filter(FLAG_SECONDS_IN_HALF != 1) %>%
        filter(!grepl("kickoff", tolower(PLAY_TYPE))) %>%
        filter(!is.na(NEXT_SCORE_EVENT_OFFENSE)) %>%
        filter(DOWN %in% c(1,2,3,4)) %>%
        filter(YARD_LINE < 100 & YARD_LINE > 0) %>%
        mutate(SECONDS_IN_HALF = plyr::round_any(SECONDS_IN_HALF, 5, ceiling)) %>%
        group_by(SECONDS_IN_HALF, NEXT_SCORE_EVENT_OFFENSE) %>%
        count() %>%
        ggplot(., aes(x=SECONDS_IN_HALF,
                      fill = NEXT_SCORE_EVENT_OFFENSE,
                      y=n))+
        geom_bar(position = 'fill',
                 stat='identity',
                 color = NA)+
        scale_fill_manual(values = score_palette)+
        theme_phil()+
        scale_x_reverse()

```

We use all of this historical data to learn the expected points from a given situation, then look at the difference in expected points from play to play - this is the intuition behind how we will value individual plays, which we can then roll up to the offense/defense/game/season level.

## Building Models

How do these various features like down, distance, yards to goal, and time remaining affect the probability of the next scoring event? We use a model to learn this relationship from historical plays. I'll now proceed to building models which I'll use for the bulk of the analysis.

I'll set up training, validation, and test sets based around the season. I'm mostly going to build the model using plays from the 2007 season onwards, as the data quality of the play by play data starts to get worse the further back we go, though I can later do some backtesting of the model on older seasons. I'll train the model using regular season plays only, but I can predict postseason plays.

I'm going to use the seasons 2007-2015 as my main training set, 2016-2019 as a validation set, and leave 2020 and 2021 as my test set that I won't look at until later on.

I want to evaluate the output of this model for later predicting games in a season, so I'm going to train the model based on the seasons in the run up to each season so that predictions are always occuring using only information available at the time.

<!-- I'm going to use the seasons of 2007-2018 as my main training set, building and evaluating the model using a leave-one-season out approach, akin to k-fold cross validation using seasons as the folds. I'll use the 2019-2020 seasons as a validation set, and leave 2021 as my test set which I won't look at till later on. -->

```{r set up training valid test splits, echo =T}

# full plays
plays_full = plays_score_events %>%
        filter(PLAY_TYPE != 'Kickoff') %>%
        arrange(SEASON, GAME_ID) %>%
        ungroup() %>%
        mutate(OFFENSE_DIVISION = case_when(HOME_TEAM == OFFENSE ~ HOME_DIVISION,
                                            HOME_TEAM == DEFENSE ~ AWAY_DIVISION),
               DEFENSE_DIVISION = case_when(AWAY_TEAM == DEFENSE ~ AWAY_DIVISION,
                                            AWAY_TEAM == OFFENSE ~ HOME_DIVISION)) %>%
        select(GAME_ID,
               DRIVE_ID,
               PLAY_ID,
               SEASON,
               SEASON_TYPE,
               HOME,
               AWAY,
               OFFENSE,
               DEFENSE,
               OFFENSE_CONFERENCE,
               DEFENSE_CONFERENCE,
               OFFENSE_DIVISION,
               DEFENSE_DIVISION,
               OFFENSE_SCORE,
               DEFENSE_SCORE,
               # OFFENSE_PLAY_NUMBER,
               # DEFENSE_PLAY_NUMBER,
               SCORING,
               PLAY_TEXT,
               PLAY_TYPE,
               NEXT_SCORE_EVENT_HOME,
               NEXT_SCORE_EVENT_HOME_DIFF,
               NEXT_SCORE_EVENT_OFFENSE,
               NEXT_SCORE_EVENT_OFFENSE_DIFF,
               YARD_LINE,
               HALF,
               PERIOD,
               MINUTES_IN_HALF,
               SECONDS_IN_HALF,
               DOWN,
               DISTANCE,
               YARD_LINE,
               YARDS_TO_GOAL) %>%
        mutate(OFFENSE_ID = factor(case_when(OFFENSE_DIVISION == 'fbs' ~ OFFENSE,
                                      TRUE ~ 'fcs')),
               DEFENSE_ID = factor(case_when(DEFENSE_DIVISION == 'fbs' ~ DEFENSE,
                                              TRUE ~ 'fcs'))) %>%
        filter(DOWN %in% c(1, 2, 3, 4)) %>%
        filter(PERIOD %in% c(1,2,3,4)) %>%
        filter(!is.na(SECONDS_IN_HALF)) %>%
        filter(DISTANCE >=0 & DISTANCE <=100) %>%
        filter(!is.na(NEXT_SCORE_EVENT_OFFENSE)) %>%
        mutate(NEXT_SCORE_EVENT_OFFENSE = factor(NEXT_SCORE_EVENT_OFFENSE,
                                                 levels = c("No_Score",
                                                            "TD",
                                                            "FG",
                                                            "Safety",
                                                            "Opp_Safety",
                                                            "Opp_FG",
                                                            "Opp_TD"))) %>%
        arrange(SEASON, GAME_ID, PLAY_ID)

# plays filter to postseason
plays_postseason = plays_full %>%
        filter(SEASON_TYPE == 'postseason')

# regular season
# training set
plays_train = plays_full %>%
        filter(SEASON_TYPE == 'regular') %>%
        filter(SEASON >= 2007 & SEASON <2016)

# validation set
plays_valid = plays_full %>%
        filter(SEASON_TYPE == 'regular') %>%
        filter(SEASON >= 2016 & SEASON <= 2020)

# test
plays_test = plays_full %>%
        filter(SEASON_TYPE == 'regular') %>%
        filter(SEASON > 2020)

# make an initial split based on previously defined splits
valid_split = make_splits(list(analysis = seq(nrow(plays_train)),
                                 assessment = nrow(plays_train) + seq(nrow(plays_valid))),
                               bind_rows(plays_train,
                                         plays_valid))

# test split
test_split = make_splits(
        list(analysis = seq(nrow(plays_train) + nrow(plays_valid)),
             assessment = nrow(plays_train) + nrow(plays_valid) + seq(nrow(plays_test))),
        bind_rows(plays_train,
                  plays_valid,
                  plays_test))

```

The outcome is the next scoring event, always defined from the perspective of the offense for any given play.

```{r outcome year over year}

plays_train %>%
        group_by(SEASON, NEXT_SCORE_EVENT_OFFENSE) %>%
        count() %>%
        ggplot(., aes(x=n,
                      fill = NEXT_SCORE_EVENT_OFFENSE,
                      y=reorder(NEXT_SCORE_EVENT_OFFENSE, n)))+
        geom_col()+
        theme_phil()+
        facet_wrap(SEASON ~.,
                   ncol = 3)+
        scale_fill_manual(values = score_palette)+
        ylab("Next Score Event")

```

### Baseline

I currently use the following as features for plays in a baseline model: 

* Quarter
* Seconds Remaining in Half 
* Down 
* Distance (logged)
* Yards to opponent's end zone
* Down and goal indicator for whether the offense is in a 'first and goal' situation

I also include interactions between down and distance, down and yards to end zone, and yards to end zone and seconds remaining. This baseline model doesn't account for things like offense/defense quality or scoring effects, meaning this analysis focused on estimating the expected points given the situation without respect to opponent.

```{r create recipes, echo=T}

baseline_recipe = recipe(NEXT_SCORE_EVENT_OFFENSE ~.,
                         data = plays_train) %>%
        update_role(all_predictors(),
                    new_role = "ID") %>%
        update_role(
                c("GAME_ID",
                  "DRIVE_ID",
                  "PLAY_ID",
                  "SEASON",
                  "SEASON_TYPE",
                  "HOME",
                  "AWAY",
                  "OFFENSE",
                  "DEFENSE",
                  "OFFENSE_ID",
                  "DEFENSE_ID",
                  "OFFENSE_DIVISION",
                  "DEFENSE_DIVISION",
                  "OFFENSE_CONFERENCE",
                  "DEFENSE_CONFERENCE",
                  "SCORING",
                  "OFFENSE_SCORE",
                  "DEFENSE_SCORE",
                  "PLAY_TEXT",
                  "PLAY_TYPE",
                  "NEXT_SCORE_EVENT_HOME",
                  "NEXT_SCORE_EVENT_HOME_DIFF",
                  "NEXT_SCORE_EVENT_OFFENSE_DIFF",
                  "YARD_LINE",
                  "MINUTES_IN_HALF",
                  "HALF"),
                new_role = "ID") %>%
        step_mutate(PERIOD_ID = PERIOD,
                    role = "ID") %>%
        # features we're inheriting
        update_role(
                c("PERIOD", 
                "SECONDS_IN_HALF",
                "DOWN",
                "DISTANCE",
                "YARDS_TO_GOAL"),
                new_role = "predictor") %>%
        # filters for issues
        step_filter(!is.na(NEXT_SCORE_EVENT_OFFENSE)) %>%
        step_filter(YARD_LINE <= 100 & YARD_LINE >=0) %>%
        step_filter(YARDS_TO_GOAL <=100 & YARD_LINE >=0) %>%
        step_filter(DOWN %in% c(1, 2, 3, 4)) %>%
        step_filter(DISTANCE >=0 & DISTANCE <=100) %>%
        step_filter(SECONDS_IN_HALF <=1800) %>%
        step_filter(!is.na(SECONDS_IN_HALF)) %>%
        step_filter(PERIOD_ID == 1 | PERIOD_ID == 2 | PERIOD_ID == 3 | PERIOD_ID == 4) %>%
        # create features
        step_mutate(KICKOFF = case_when(grepl("kickoff", tolower(PLAY_TEXT)) | grepl("kickoff", tolower(PLAY_TYPE))==T ~ 1,
                                        TRUE ~ 0),
                    role = "id") %>%
        step_mutate(TIMEOUT = case_when(grepl("timeout", tolower(PLAY_TEXT)) ~ 1,
                                        TRUE ~ 0),
                    role = "id") %>%
        step_filter(TIMEOUT != 1) %>%
        step_filter(KICKOFF != 1) %>%
        step_mutate(DOWN_TO_GOAL = case_when(DISTANCE == YARDS_TO_GOAL ~ 1,
                                             TRUE ~ 0)) %>%
        step_mutate(DOWN = factor(DOWN)) %>%
        step_mutate(PERIOD = factor(PERIOD)) %>%
        step_log(DISTANCE, offset =1) %>%
        step_dummy(all_nominal_predictors()) %>%
        step_novel(all_nominal_predictors(),
                   new_level = "new") %>%
        step_interact(terms = ~ DISTANCE:(starts_with("DOWN_"))) %>%
        step_interact(terms = ~ YARDS_TO_GOAL:(starts_with("DOWN_"))) %>%
        step_interact(terms = ~ YARDS_TO_GOAL*SECONDS_IN_HALF) %>%
        check_missing(all_predictors()) %>%
        step_zv(all_predictors()) %>%
        step_normalize(all_numeric_predictors())

```

## Workflows

I'll define the model I'll be using here, which is a multinomial logistic regression.

```{r define model objs, echo=T}

# from glmnet
multinom_mod = multinom_reg(
  mode = "classification",
  engine = "glmnet",
  penalty = 0,
  mixture = NULL
)

```

I'll then create a workflow, which will allow me to apply the recipe and the model estimation in one go.

```{r craete workflow, echo=T}

# create baseline
baseline_wf = workflow() %>%
        add_recipe(baseline_recipe) %>%
        add_model(multinom_mod)

# workflow settings
# metrics
class_metrics<-metric_set(yardstick::roc_auc,
                          yardstick::mn_log_loss)

# control for resamples
keep_pred <- control_resamples(save_pred = TRUE, 
                               save_workflow = TRUE,
                               allow_par=T)

```


```{r rm recipes}

# At this point I can remove the recipes, as they're now embedded in the workflows.
rm(baseline_recipe)

```

```{r register parallel cores, include=F}

# register parallel
library(doParallel)
numcores = parallel::detectCores()
registerDoParallel(numcores -2)

```


## Training

I'll now fit the model on the training set and predict the validation set.

```{r fit to training set, echo=T, eval=T}

# fit the model to the whole training set
last_fit_baseline = baseline_wf %>%
        last_fit(split = valid_split)
                 
```

```{r pluck the trained workflow}

# pluck workflow
fit_baseline = last_fit_baseline %>%
        pluck(".workflow", 1)

```

## Model Performance

We can evaluate the model via a leave-one-season out approach, or via some in sample metrics of fit, but I'll predict the validation set as check. I'll compare performance relative to a null model that simply predicts the incidence rate of each outcome in the training set.

```{r predict validation set}

# predict with baseline
preds_baseline = fit_baseline %>%
        predict(new_data = plays_valid,
                type = 'prob') %>%
        bind_cols(., 
                  fit_baseline %>%
                          predict(new_data = plays_valid)) %>%
        bind_cols(plays_valid,
                  .) %>%
        mutate(method = 'baseline')

```


```{r get null preds}

# baseline rates in training set
train_rates = plays_train %>%
        group_by(NEXT_SCORE_EVENT_OFFENSE) %>%
        count() %>%
        ungroup() %>%
        mutate(prop = n / sum(n))

# predict null for all valid
preds_null = train_rates %>% 
        select(-n) %>%
        spread(NEXT_SCORE_EVENT_OFFENSE, prop) %>% 
        set_names(., paste(".pred_", names(.), sep="")) %>%
        mutate(.pred_class = factor('TD',
                                    levels = c("TD",
                                      "FG",
                                      "Safety",
                                      "No_Score",
                                      "Opp_Safety",
                                      "Opp_FG",
                                      "Opp_TD"))) %>%
        bind_cols(plays_valid,
                  .)
```


```{r yardstick assessment on validation, warning=F, message=F}

# roc_auc
bind_rows(preds_null %>%
                  mutate(method = 'null'),
          preds_baseline %>%
                  mutate(method = 'baseline')) %>%
          # preds_defense_adjusted %>%
          #         mutate(method = 'defense_adjusted'),
          # preds_offense_adjusted %>%
          #         mutate(method = 'offense_adjusted')) %>%
        group_by(method) %>%
        yardstick::roc_auc(
                   NEXT_SCORE_EVENT_OFFENSE,
                   `.pred_No_Score`:`.pred_Opp_TD`,
           #        estimator = 'macro_weighted'
                   ) %>%
        mutate_if(is.numeric, round, 3) %>%
        arrange(desc(.estimate)) %>%
        flextable() %>%
        autofit()

# logloss
bind_rows(preds_null %>%
                  mutate(method = 'null'),
          preds_baseline %>%
                  mutate(method = 'baseline')) %>%
          # preds_defense_adjusted %>%
          #         mutate(method = 'defense_adjusted'),
          # preds_offense_adjusted %>%
          #         mutate(method = 'offense_adjusted')) %>%
        group_by(method) %>%
        yardstick::mn_log_loss(
                   NEXT_SCORE_EVENT_OFFENSE,
                   `.pred_No_Score`:`.pred_Opp_TD`,
           #        estimator = 'macro_weighted'
                   ) %>%
        mutate_if(is.numeric, round, 3) %>%
        arrange(.estimate) %>%
        flextable() %>%
        autofit()

```

What we really care about is the calibration of the predictions - does the observed incidence rate of events match the predicted probabilities from the model? That is, when the model predicts that the next scoring event has a probability of 0.5 of being a TD, do we observe TDs occur about half of the time?

```{r get indidence}

last_fit_baseline %>% 
        pluck(".predictions", 1) %>%
        select(-.pred_class) %>%
        gather("class", ".pred", 
               - .row, -NEXT_SCORE_EVENT_OFFENSE, -.config) %>%
        mutate(class = gsub(".pred_", "", class)) %>%
        mutate(.pred_bin = plyr::round_any(.pred, .025)) %>%
        group_by(class, .pred_bin) %>%
        mutate(number_preds = n_distinct(.row)) %>%
        group_by(.pred_bin, class, NEXT_SCORE_EVENT_OFFENSE, number_preds) %>%
        count() %>%
        filter(NEXT_SCORE_EVENT_OFFENSE == class) %>%
        mutate(prop = n / number_preds) %>%
        ggplot(., aes(x=.pred_bin,
                      size  = number_preds,
                      y = prop))+
        geom_point()+
        geom_abline(slope = 1,
                    intercept = 0,
                    linetype = 'dashed')+
        xlab("Predicted Probability of Score Event")+
        ylab("Observed Probability of Score Event")+
        facet_wrap(NEXT_SCORE_EVENT_OFFENSE ~.)+
        theme_phil()+
        theme(legend.title = element_text())+
        guides(size = guide_legend(title = 'Number of Plays',
                                  title.position = 'top'))+
        ggtitle("Calibration of Predictions by Outcome on Validation Set",
                subtitle = str_wrap("Observed vs predicted incident rate of next scoring event from multinomial logistic regression.", 120))


```

## Inference

Understanding partial effects from a multinomial logit is already difficult, and I've thrown a bunch of interactions in there to make this even more difficult. We can extract the coefficients and take a look, but really in order to interpret the model we need to use predicted probabilities.

```{r get coefs, fig.height=10, fig.width=8, warning=F, message=F}

tidy(fit_baseline) %>%
        mutate(term = factor(term)) %>%
        mutate(term = relevel(term, ref = "(Intercept)")) %>%
        ggplot(., aes(y=term,
                      x=estimate))+
        geom_point()+
        facet_wrap(class~.)+
        theme_bw()+
        ggtitle("Coefficients from Baseline Multinomial Logistic Regression")

```

I'll look at predicted probabilities using an observed values approach for particular features (using a sample rather than the full dataset to save time). This means taking the model and then altering the feature of interest for every observation and taking the average predicted probability for each outcome across all observations.

How is the probability of the next scoring event influenced by where the offense has possession?

```{r look at defense fixed effect}

# define min and max for feature
setting = seq(1, 100,
              2)

# loop over
pred_settings = foreach(i = 1:length(setting),
        .combine = bind_rows) %do% {
                
                set.seed(1999)
                sample_plays =  plays_train %>%
                        sample_n(50000) %>%
                        mutate(YARDS_TO_GOAL = setting[i])
                
                fit_baseline %>%
                        predict(new_data = sample_plays, type = 'prob') %>%
                        bind_cols(., sample_plays) %>%
                        group_by(YARDS_TO_GOAL) %>%
                        summarize(.pred_No_Score = mean(.pred_No_Score),
                                  .pred_TD = mean(.pred_TD),
                                  .pred_FG = mean(.pred_FG),
                                  .pred_Safety = mean(.pred_Safety),
                                  .pred_Opp_Safety = mean(.pred_Opp_Safety),
                                  .pred_Opp_FG = mean(.pred_Opp_FG),
                                  .pred_Opp_TD = mean(.pred_Opp_TD)) %>%
                        gather("outcome", ".pred",
                               -YARDS_TO_GOAL)
}

```


```{r now examine predicted probabilities}

# now plot this effect

# now plot this effect
pred_settings %>%
        mutate(outcome = paste(gsub(".pred_", "Pr(", outcome), ")", sep="")) %>%
             mutate(outcome = factor(outcome,
                                levels = paste("Pr(", c("TD",
                                      "FG",
                                      "Safety",
                                      "No_Score",
                                      "Opp_Safety",
                                      "Opp_FG",
                                      "Opp_TD"),
                                      ")",
                                      sep =""))) %>%
        ggplot(., 
               aes(x=YARDS_TO_GOAL,
               y = .pred,
               color = outcome,
               group = outcome))+
        facet_wrap(outcome ~.,
                   ncol = 4)+
        geom_line(lwd=1.1)+
        # scale_color_viridis_d(option = 'B',
        #                    end = 0.8,
        #                    begin = 0.2)+        
        scale_color_manual(values = score_palette)+
        theme_phil()+
        theme(legend.title = element_text())+
        guides(color = guide_legend(title = 'Next Scoring Event',
                                    title.position = 'top'))+
        xlab("Yards to Opponent End Zone")+
        ylab("Pr(Next Scoring Event)")+
        coord_cartesian(ylim= c(0, 1))+
        geom_vline(xintercept = 50,
                   linetype = 'dotted')+
        ggtitle("Probability of Next Scoring Event by Offensive Field Position",
                subtitle = str_wrap("Predicted probabilities from multinomial logistic regression. Displaying probabilities using observed values approach for a sample of training set. Model trained on regular season college football plays from 2007-2015. ",
                                    120))

# now plot this effect
pred_settings %>%
        mutate(outcome = paste(gsub(".pred_", "Pr(", outcome), ")", sep="")) %>%
             mutate(outcome = factor(outcome,
                                levels = paste("Pr(", c("TD",
                                      "FG",
                                      "Safety",
                                      "No_Score",
                                      "Opp_Safety",
                                      "Opp_FG",
                                      "Opp_TD"),
                                      ")",
                                      sep =""))) %>%
        ggplot(., 
               aes(x=YARDS_TO_GOAL,
               y = .pred,
               fill = outcome,
               group = outcome))+
        geom_col(position = 'fill',
                 lwd=1.1)+
        # scale_fill_viridis_d(option = 'B',
        #                    end = 0.8,
        #                    begin = 0.2)+        
        scale_fill_manual(values = score_palette)+
        theme_phil()+
        theme(legend.title = element_text())+
        guides(fill = guide_legend(title = 'Next Scoring Event',
                                    title.position = 'top'))+
        xlab("Yards to Opponent End Zone")+
        ylab("Pr(Next Scoring Event)")+
        coord_cartesian(ylim= c(0, 1))+
        geom_vline(xintercept = 50,
                   linetype = 'dotted')+
        ggtitle("Probability of Next Scoring Event by Offensive Field Position",
                subtitle = str_wrap("Predicted probabilities from multinomial logistic regression. Displaying probabilities using observed values approach for a sample of training set. Model trained on regular season college football plays from 2007-2015. ",
                                    120))


```

How is this affected by the down?

```{r loop over yards to goal and down}

# define min and max for feature
setting_1 = seq(1, 100, 5)
setting_2 = c(1, 2, 3, 4)

# loop over both
pred_settings_12 = foreach(i = 1:length(setting_1),
                        .combine = bind_rows) %:% 
        foreach(j = 1:length(setting_2)) %do% {
                
                set.seed(1999)
                 fit_baseline %>%
                        predict(new_data = plays_train %>% 
                                        sample_n(50000) %>%
                                        mutate(YARDS_TO_GOAL = setting_1[i],
                                               DOWN = setting_2[j]),
                                type = 'prob') %>%
                        apply(., 2, mean) %>%
                        as.data.frame() %>%
                        rownames_to_column("outcome") %>% 
                        set_names(., c("outcome", ".pred")) %>%
                        mutate(YARDS_TO_GOAL = setting_1[i],
                               DOWN = setting_2[j])
                
        }
                
```

```{r look at predicted probs by down and yards to goal}

# now plot this effect
pred_settings_12 %>%
        mutate(outcome = paste(gsub(".pred_", "Pr(", outcome), ")", sep="")) %>%
             mutate(outcome = factor(outcome,
                                levels = paste("Pr(", c("TD",
                                      "FG",
                                      "Safety",
                                      "No_Score",
                                      "Opp_Safety",
                                      "Opp_FG",
                                      "Opp_TD"),
                                      ")",
                                      sep =""))) %>%
        mutate(DOWN = factor(DOWN)) %>%
        ggplot(., 
               aes(x=YARDS_TO_GOAL,
               y = .pred,
               color = DOWN,
               group = DOWN))+
        facet_wrap(outcome ~.,
                   ncol = 4)+
        geom_line(lwd=1.1)+
        scale_color_viridis_d(option = 'D',
                           begin = 0.2)+        
        theme_phil()+
        theme(legend.title = element_text())+
        guides(color = guide_legend(title = 'Down',
                                    title.position = 'top'))+
        xlab("Yards to Opponent End Zone")+
        ylab("Pr(Next Scoring Event)")+
        ggtitle("Probability of Next Scoring Event by Offensive Field Position and Down",
                subtitle = str_wrap("Predicted probabilities from multinomial logistic regression. Displaying probabilities using observed values approach for a sample of training set. Model trained on regular season college football plays from 2007-2015. ",
                                    120))

```

How does this translate into expected points?

```{r expected points by distance and down}

# loop over both
point_settings_12 = foreach(i = 1:length(setting_1),
                        .combine = bind_rows) %:% 
        foreach(j = 1:length(setting_2)) %do% {
                
                set.seed(1999)
                 fit_baseline %>%
                        predict(new_data = plays_train %>% 
                                        sample_n(50000) %>%
                                        mutate(YARDS_TO_GOAL = setting_1[i],
                                               DOWN = setting_2[j]),
                                type = 'prob') %>%
                         expected_points_func %>%
                         summarize(EP = mean(EP)) %>%
                        mutate(YARDS_TO_GOAL = setting_1[i],
                               DOWN = setting_2[j])
                
        }

```

```{r plot expected points by distance and down}

# now plot this effect
point_settings_12 %>%
        mutate(DOWN = factor(DOWN)) %>%
        ggplot(., 
               aes(x=YARDS_TO_GOAL,
               y = EP,
               color = DOWN,
               group = DOWN))+
        # facet_wrap(outcome ~.,
        #            ncol = 4)+
        geom_line(lwd=1.1)+
        scale_color_viridis_d(option = 'D',
                           begin = 0.2)+        
        theme_phil()+
        geom_hline(yintercept = 0,
                   linetype = 'dashed')+
        theme(legend.title = element_text())+
        guides(color = guide_legend(title = 'Down',
                                    title.position = 'top'))+
        xlab("Yards to Opponent End Zone")+
        ylab("Expected Points")+
        ggtitle("Expected Points by Offensive Field Position and Down",
                subtitle = str_wrap("Expected points using probabilities from multinomial logistic regression. Displaying expected points a portion of the training set using observed values approach, Model trained on regular season college football plays from 2007-2015. ",
                                    120))+
        geom_vline(xintercept = 50,
                   linetype = 'dotted')

```

```{r rm objects from memory}

rm(pred_settings,
   pred_settings_12,
   point_settings_12,
   sample_plays)

```

I'll now retrain the model on the validation set and predict the test set so I can save the model's predictions for every play. I won't take a look at these predictions until I've done some more analysis, but I'll score them anyway.

```{r get predictions for training and validation}

# plays from the training set
predicted_plays_train = 
        augment(fit_baseline, 
                new_data = plays_train) %>%
        mutate(type = 'train')

# plays from the validation set
predicted_plays_valid = 
        last_fit_baseline %>%
        pluck(".predictions", 1) %>%
        mutate(type = 'valid') %>%
        bind_cols(., plays_valid %>%
                          select(-NEXT_SCORE_EVENT_OFFENSE)) %>%
        select(-.config, -.row)

# predict postseason for these seasons
predicted_plays_postseason_valid = augment(fit_baseline,
                                           new_data = plays_postseason %>%
                                                   filter(SEASON < 2020)) %>%
        mutate(type = 'valid')

rm(fit_baseline,
   last_fit_baseline)

```

```{r now do a final fit}

# get predictions for test set
final_fit_baseline = baseline_wf %>%
        last_fit(split = test_split)

# now predict tests
predicted_plays_test = 
        final_fit_baseline %>%
        pluck(".predictions", 1) %>%
        mutate(type = 'test') %>%
        bind_cols(., plays_test %>%
                          select(-NEXT_SCORE_EVENT_OFFENSE)) %>%
        select(-.config, -.row)

# now predict tests
predicted_plays_postseason_test = augment(final_fit_baseline %>%
                                                  pluck(".workflow", 1),
                                           new_data = plays_postseason %>%
                                                   filter(SEASON >= 2020)) %>%
        mutate(type = 'test')

```


```{r get predictions}

# combine
predicted_plays = bind_rows(predicted_plays_train,
                            predicted_plays_valid,
                            predicted_plays_postseason_valid,
                            predicted_plays_test,
                            predicted_plays_postseason_test)

save(predicted_plays,
     file = here::here("data/predicted_plays.Rdata"))

```


```{r save workflow}

expected_points_model = final_fit_baseline %>%
        pluck(".workflow", 1)

# save(expected_points_model,
#      file = here::here("workflows", "expected_points_model.R"))

```

That's enough of this writeup, I'll proceed to examining expected points added in the next section.

```{r save with vetiver}

library(vetiver)

expected_points_mod <- vetiver_model(expected_points_model, "expected_points")

```

```{r pin}

library(pins)

# set as bpard
model_board <- board_folder(path = here::here("models"),
                          versioned = TRUE)
# pin to board
model_board %>% 
        vetiver_pin_write(expected_points_mod)

```

